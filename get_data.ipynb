{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Clean Text Data\n",
    "\n",
    "Trained on a mixture of text from the following sources:\n",
    "- The complete works of William Shakespeare from https://www.gutenberg.org/cache/epub/100/pg100.txt\n",
    "- Collection of 40 books from https://huggingface.co/datasets/IsmaelMousa/books (https://huggingface.co/datasets/IsmaelMousa/books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "import re\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "datasets_path = \"datasets/bee_hummingbird\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Complete Works of William Shakespeare\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    Contents\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download shakepeare dataset using requests\n",
    "gutenberg_response = requests.get(\"https://www.gutenberg.org/cache/epub/100/pg100.txt\")\n",
    "assert gutenberg_response.status_code == 200, \"Failed to download the dataset\"\n",
    "\n",
    "with open(f\"{datasets_path}/shakespeare.txt\", \"w\") as f:\n",
    "    f.write(gutenberg_response.text)\n",
    "    \n",
    "with open(f\"{datasets_path}/shakespeare.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "    marker_start_list = [line  for line in content if \"*** START OF THE PROJECT GUTENBERG EBOOK\" in line]\n",
    "    marker_start = marker_start_list[0]\n",
    "    marker_end = [line for line in content if \"*** END OF THE PROJECT GUTENBERG EBOOK\" in line][0]\n",
    "    main_content = \"\".join(content[content.index(marker_start)+1:content.index(marker_end)])\n",
    "    \n",
    "with open(f\"{datasets_path}/shakespeare.txt\", \"w\") as f:\n",
    "    f.write(main_content)\n",
    "\n",
    "print(main_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downlod data from datasets and save it to a file\n",
    "train_books_dataset = load_dataset(\"IsmaelMousa/books\")[\"train\"]\n",
    "validation_books_dataset = load_dataset(\"IsmaelMousa/books\")[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{datasets_path}/books.txt\", \"w\") as f:\n",
    "    for book in train_books_dataset:\n",
    "        f.write(book[\"EN\"])\n",
    "        f.write(\"\\n\\n************\\n\\n\")\n",
    "    for book in validation_books_dataset:\n",
    "        f.write(book[\"EN\"])\n",
    "        f.write(\"\\n\\n************\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚒️ **Manual Data preparation/selection**:\n",
    "- combine the books into one text file, separated by \"*************\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_standardize(text):\n",
    "    \"\"\"\n",
    "    fixes some issues the spacy tokenizer had on books corpus\n",
    "    also does some whitespace standardization\n",
    "    \"\"\"\n",
    "    text = text.replace('—', '-')\n",
    "    text = text.replace('–', '-')\n",
    "    text = text.replace('―', '-')\n",
    "    text = text.replace('…', '...')\n",
    "    text = text.replace('´', \"'\")\n",
    "    text = re.sub('''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)''', r' \\1 ', text)\n",
    "    text = re.sub('\\s*\\n\\s*', ' \\n ', text)\n",
    "    text = re.sub('[^\\S\\n]+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was born in the year 1632 , in the city of York , of a good family , \n",
      " though not of that country \n",
      "From fairest creatures we desire increase , \n",
      " That thereby beauty's rose might never die , \n",
      " But as \n"
     ]
    }
   ],
   "source": [
    "with open(f\"{datasets_path}/books.txt\", \"r\") as f:\n",
    "    books = f.read()\n",
    "with open(f\"{datasets_path}/shakespeare.txt\", \"r\") as f:\n",
    "    shakespeare = f.read()\n",
    "books = text_standardize(ftfy.fix_text(books))\n",
    "shakespeare = text_standardize(ftfy.fix_text(shakespeare))\n",
    "print(books[:100])\n",
    "print(shakespeare[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32817514, 5725829, 38543343)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books), len(shakespeare), len(books)+len(shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the character set of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"$&\\'()*+,-./0123456789:;=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(list(set(books))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n, ,!,\",&,\\',(,),*,,,-,.,1,2,3,4,5,6,7,8,9,:,;,?,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,[,],_,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,À,Æ,Ç,É,à,â,æ,ç,è,é,ê,ë,î,œ'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(sorted(list(set(shakespeare))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular and least popular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 292752),\n",
       " ('and', 183155),\n",
       " ('of', 160470),\n",
       " ('to', 154686),\n",
       " ('a', 118032),\n",
       " ('I', 113963),\n",
       " ('in', 89919),\n",
       " ('was', 74017),\n",
       " ('that', 72529),\n",
       " ('he', 60213),\n",
       " ('it', 56483),\n",
       " ('his', 53726),\n",
       " (';', 52675),\n",
       " ('had', 49471),\n",
       " ('you', 46628),\n",
       " ('with', 46372),\n",
       " ('as', 42928),\n",
       " ('for', 40417),\n",
       " ('not', 39522)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = dict(Counter(books.split()))\n",
    "sorted_dict = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "[sorted_dict[i] for i in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ihope', 1),\n",
       " ('astronomy.', 1),\n",
       " ('gid.', 1),\n",
       " ('gibberedBig', 1),\n",
       " ('gibing', 1),\n",
       " ('enhancement', 1),\n",
       " ('Vainand', 1),\n",
       " ('Apia', 1),\n",
       " ('tangle:', 1),\n",
       " ('marvelling.', 1),\n",
       " ('jd', 1),\n",
       " ('Sl', 1),\n",
       " ('carnivores', 1),\n",
       " ('ninepin.', 1),\n",
       " ('raft.', 1),\n",
       " ('generalised', 1),\n",
       " ('ursine', 1),\n",
       " ('Familycages', 1),\n",
       " ('thoseHappy', 1)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sorted_dict[-i] for i in range(1,20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save combined text to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{datasets_path}/combined_data.txt\", \"w\") as f:\n",
    "    f.write(shakespeare+\"\\n\"+books)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
